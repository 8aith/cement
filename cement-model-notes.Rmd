Notes on cement modeling
========================================================

Here are the best regression models we've come up with:

```{r loaddata}
require(earth)
require(ggplot2)
source("cement-util.R")
master.table <- dget(file="cement-table.dat")
master.table <- master.table[master.table$year %% 5 == 1,]
testing.countries <- dget(file="testing-countries.dat")
set.seed(8675309)
```

Cluster with and without the modified population density.  Well use 4-5 clusters for the basic, 4-6 for the population density:

```{r docluster}
basic.predictors <- c("GDP.rate", "pcGDP", "urban.growth", "urban.pop", "pop.rate")
pden.predictors  <- c(basic.predictors, "pop.den")
## Lists of vars that include the output variable and the ISO code.  We need these to 
## filter the master table appropriately
basic.fullvars <- c(basic.predictors, "pcc.rate", "ISO", "year")
basic.numvars  <- c(basic.predictors, "pcc.rate")
pden.fullvars  <- c(pden.predictors, "pcc.rate", "ISO", "year")
pden.numvars   <- c(basic.predictors, "pcc.rate")

basic.table <- select.complete(master.table[,basic.fullvars])
basic.normalized <- clust.normalize(basic.table[,basic.predictors])
km.basic.4 <- kmeans(basic.normalized, centers=4)
km.basic.5 <- kmeans(basic.normalized, centers=5)

pden.table <- select.complete(master.table[,pden.fullvars])
pden.normalized <- clust.normalize(pden.table[,pden.predictors])
km.pden.4 <- kmeans(pden.normalized, centers=4)
km.pden.5 <- kmeans(pden.normalized, centers=5)
km.pden.6 <- kmeans(pden.normalized, centers=6)
```

Show the boxplots for the clusters, to give us an idea of what they cover.  Note we include the output variable, even if we didn't cluster on it  Clusters with basic vars:

```{r clustplot.basic, fig.width=10}
cluster.boxplot(km.basic.4, basic.table, basic.numvars)
cluster.boxplot(km.basic.5, basic.table, basic.numvars)
```

Clusters including (modified) population density:
```{r clustplot.pden, fig.width=10, fig.height=10}
cluster.boxplot(km.pden.4, pden.table, pden.numvars)
cluster.boxplot(km.pden.5, pden.table, pden.numvars)
cluster.boxplot(km.pden.6, pden.table, pden.numvars)
```

How similar are these clusters?  Check the similarity matrices
```{r simmatrix}
basic.members.4 <- clust.members(basic.table, km.basic.4$cluster)
basic.members.5 <- clust.members(basic.table, km.basic.5$cluster)
mlist.sim.matrix(basic.members.4, basic.members.4)
mlist.sim.matrix(basic.members.5, basic.members.5)
mlist.sim.matrix(basic.members.4, basic.members.5)

pden.members.4 <- clust.members(pden.table, km.pden.4$cluster)
pden.members.5 <- clust.members(pden.table, km.pden.5$cluster)
pden.members.6 <- clust.members(pden.table, km.pden.6$cluster)
mlist.sim.matrix(pden.members.4, pden.members.4)
mlist.sim.matrix(pden.members.5, pden.members.5)
mlist.sim.matrix(pden.members.6, pden.members.6)
mlist.sim.matrix(pden.members.4, pden.members.5)
mlist.sim.matrix(pden.members.4, pden.members.6)
mlist.sim.matrix(pden.members.5, pden.members.6)
```

Based on this it looks like the 6-cluster pden model might be kind of splitting cluster 5.1 into 6.3 and 6.4.  For the time being, I'm going to drop it.  (We need a better way of evaluating the clustering.  Maybe 5.1 _should_ have been split.  Look into measures of compactness.)

Comparing clusters with different sets of predictors is kind of tricky because the input datasets are (potentially) different.  For now we'll just do the modeling on each group of clusters separately and compare the results.

```{r fitmodels}
## same as basic.predictors and pden.predictors above, but expressed as a formula
basic.f <- pcc.rate~GDP.rate + pcGDP + urban.growth + urban.pop + pop.rate
pden.f  <- pcc.rate~pcGDP + GDP.rate + urban.growth + urban.pop + pop.rate + pop.den

## split basic data set into testing and training sets
basic.split <- master.table[complete.cases(master.table[,basic.fullvars]),]
basic.split <- split(basic.split, basic.split$ISO %in% testing.countries)
names(basic.split) <- c("training","testing")

## Fit the whole dataset with degre=1 and degree=2.  
basic.lm <- lm(formula=basic.f, data=basic.split$training)
basic.earth.d1 <- earth(formula=basic.f, data=basic.split$training, degree=1)
basic.earth.d2 <- earth(formula=basic.f, data=basic.split$training, degree=2)


## Evaluate RMS errors.  The rms.eval function wants a list of testing and training 
## datasets, which we don't really have (yet), so insert a dummy for the testing set
rms.eval(basic.lm, basic.split, prn=FALSE)
rms.eval(basic.earth.d1, basic.split, prn=FALSE)
rms.eval(basic.earth.d2, basic.split, prn=FALSE)
  
```

The earth model with the basic parameters and degree 1 seems to be our best contender so far.  Degree 2 does better on the training set, but worse on the training set, a clear indicator of overfitting.  Here's the scatterplot for that and for the basic linear model:

```{r scatterplot.earth.basic.d1}
scatterplot.model(basic.lm, basic.split, sz=2)
scatterplot.model(basic.earth.d1, basic.split, sz=2)
```

The cluster results are also intriguing. Cross-validation is complicated by the fact that the testing countries don't fall evenly across the clusters, so we've only done it in a limited way.

```{r cluster5}
cmodel.basic.5.lm <- cluster.regression(km.basic.5, basic.table, formula=basic.f, fitfun=lm, testset=testing.countries)
cmodel.basic.5.d1 <- cluster.regression(km.basic.5, basic.table, formula=basic.f, fitfun=earth, degree=1)
cmodel.basic.5.d1alt <- cluster.regression(km.basic.5, basic.table, formula=basic.f, fitfun=earth, testset=testing.countries, degree=1)
cmodel.basic.5.d2 <- cluster.regression(km.basic.5, basic.table, formula=basic.f, fitfun=earth, degree=2)
cmodel.pden.5.lm <- cluster.regression(km.pden.5, pden.table, formula=pden.f, fitfun=lm, testset=testing.countries)
cmodel.pden.5.d1 <- cluster.regression(km.pden.5, pden.table, formula=pden.f, fitfun=earth, degree=1)
cmodel.pden.5.d2 <- cluster.regression(km.pden.5, pden.table, formula=pden.f, fitfun=earth, degree=2)

cluster.rms.eval(km.basic.5, basic.table, cmodel.basic.5.lm, prn=FALSE, testing.set=testing.countries)
cluster.rms.eval(km.basic.5, basic.table, cmodel.basic.5.d1, prn=FALSE, testing.set=testing.countries)
cluster.rms.eval(km.basic.5, basic.table, cmodel.basic.5.d1alt, prn=FALSE, testing.set=testing.countries)
cluster.rms.eval(km.basic.5, basic.table, cmodel.basic.5.d2, prn=FALSE, testing.set=testing.countries)

cluster.rms.eval(km.pden.5, pden.table, cmodel.pden.5.lm, prn=FALSE, testing.set=testing.countries)
cluster.rms.eval(km.pden.5, pden.table, cmodel.pden.5.d1, prn=FALSE, testing.set=testing.countries)
cluster.rms.eval(km.pden.5, pden.table, cmodel.pden.5.d2, prn=FALSE, testing.set=testing.countries)
```

The degree 2 looks slightly better.  Here are the scatterplots:

```{r cluster.scatterplot}
cluster.scatterplot.model(km.basic.5, basic.table, cmodel.basic.5.d2, sz=2)
cluster.scatterplot.model(km.pden.5, pden.table, cmodel.pden.5.d2, sz=2)
```

The degree 2 fits look a little suspect.  Clusters 2 and 4 (basic) are being fit mostly by the intercept term.  Likewise cluster 5 in the pden version.

How do the models differ with and without the clustering (and with different versions of the clustering)?  Here are the model summaries for the straight linear model.

```{r model.summaries}
summary(basic.lm)
lapply(cmodel.basic.5.lm, summary)
lapply(cmodel.pden.5.lm, summary)
```

Interesting.  It looks like GDP.rate is the only one that is consistently significant.  That isn't too surprising.  Much of the information in the other variables has been extracted by the clustering process.  This suggests a new approach:  cluster on the indicators excluding GDP.rate, then fit a simple model with just GDP.rate (possibly including an intercept) to each cluster.

**NB: I changed the predictor to pcGDP.rate in a subsequent draft in order to facilitate comparison with GCAM**

```{r simple.clustering, fig.width=10, fig.height=8}
simple.clustervars <- c("pcGDP", "urban.growth", "urban.pop", "pop.rate")
simple.extravars   <- c("pcGDP.rate", "pcc.rate")
simple.plotvars    <- c(simple.clustervars, simple.extravars)
simple.f           <- pcc.rate ~ pcGDP.rate

pden.clustervars   <- c("pcGDP", "urban.growth", "urban.pop", "pop.rate", "pop.den")
pden.extravars     <- simple.extravars
pden.plotvars      <- c(pden.clustervars, pden.extravars)
pden.f             <- simple.f

## Also fit the plain linear model, which we can get by doing just one cluster.
gcam  <- cluster.model(master.table, simple.clustervars, simple.extravars, simple.f, 1,
                        testset=testing.countries)
simple <- cluster.model(master.table, simple.clustervars, simple.extravars, simple.f, 5,
                                   testset=testing.countries)
pden   <- cluster.model(master.table, pden.clustervars, pden.extravars, pden.f, 5,
                                   testset=testing.countries)

cluster.boxplot(simple$km, simple$table, simple.plotvars)
cluster.boxplot(pden$km, pden$table, pden.plotvars)
```

Encouraging.  We don't get any clusters that have all the low-growth or high-growth entries like we did before.  Let's see how the models do.  Let's take a look at the countries in the simple clusters.

```{r simple.countries}
simple.countries <- simple.countries <- clust.countries(simple$table, simple$km$cluster)
simple.countries
mlist.sim.matrix(simple.countries, simple.countries)
```

```{r simple.modeling}
cluster.rms.eval(gcam$km, gcam$table, gcam$model, testing.set=testing.countries)
cluster.rms.eval(simple$km, simple$table, simple$model, testing.set=testing.countries)
cluster.rms.eval(pden$km, pden$table, pden$model, testing.set=testing.countries)
cluster.scatterplot.model(gcam$km, gcam$table, gcam$model, sz=2)
cluster.scatterplot.model(simple$km, simple$table, simple$model, sz=2)
cluster.scatterplot.model(pden$km, pden$table, pden$model, sz=2)
```

So, it's slightly better than the unclustered linear model (as measured by RMS error), but not hugely so.  Including the population density seems to make no discernible difference, so we'll drop it from here on.  Let's see the model coefficients.

```{r simple.coefs}
lapply(gcam$model, summary)
lapply(simple$model, summary)
```

Notice that some of them are similar to the ones we got from the basic.lm model, while others are rather different.  What does it mean in practice?  Let's take China as an example:

```{r chn.example}
country.clust("CHN", simple$table, simple$km$cluster, simple$model)
```

So, sometime around 2000 China moves from group 3 (roughly speaking:  poor, lightly urbanized countries) to group 1 (roughly speaking:  middle-income, urbanizing countries). When this happens, the coefficient for its GDP growth rate becomes smaller, though the intercept term offsets that, to some extent.

