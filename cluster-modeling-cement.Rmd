---
output:
  word_document: default
  html_document:
    toc: yes
---
Clustering Analysis for GCAM:  Cement Modeling
========================================================

```{r loaddata, echo=FALSE, message=FALSE}
require(ggplot2)
source("cement-util.R")
master.table <- dget(file="cement-table.dat")
master.table <- master.table[master.table$year %% 5 == 1,]
testing.countries <- dget(file="testing-countries.dat")
set.seed(8675309)
```

## Overview of the Model

The dominant predictors for per-capita cement production are GDP growth rate and the previous period's production.  This suggests modeling cement production growth rates in terms of GDP growth rates.  Happily, this is very similar to the model that GCAM uses, which makes it easier to compare results.  The regression formula I used is 
$$\log \left(\frac{d(t)}{d(t-5)}\right) = \beta_0 + \beta_1 \log \left(\frac{g(t)}{g(t-5)}\right) + \ldots,$$
where $d$ is per-capita cement demand, $t$ is the time in years, and $g$ is per-capita GDP.  The ellipsis represents terms for additional predictors that were tried during the project.

Another method I used to introduce other predictors was to cluster the data using those predictors and then fit a model separately to the data in each cluster.  When using this technique it seems that it is generally not advisable to include the predictors used in the clustering in the regression model.  The reason for this is that within a cluster the data have similar values for some or all of the clustering variables.  Therefore, the regression coefficients for these predictors often turn out not to be statistically significant in the regression fits.  In essence, they add to the model complexity while providing very little improvement in the model's fidelity.  

In the end, I wound up using all of the additional predictors in the clustering analysis, leaving only the intercept and $g$ terms in the regression model.  This gives us a model that is readily interpretable.  The clusters line up well with existing country classifications, and there are only two regression coefficients for each cluster.  The predictors used were:

Clustering variables | Regression variables
-------------------- | --------------------
per-capita GDP (**pcGDP**) | per-capita GDP growth factor (predictor) (**pcGDP.rate**)
urbanization fraction (**urban.pop**) | per-capita cement growth factor (response) (**pcc.rate**)
urban population growth rate (**urban.growth**) |  -
total population growth rate (**pop.rate**) |  -

In addition, I considered a modified population density statistic (calculated from gridded population data, with grid cells below a certain population threshold not considered for either population or area), but I eventually elected not to include it because it added little value and is probably not practical to use in GCAM.

You may be wondering at this point what happened to the "MARS" models that I talked so much about early in the project.  The answer is that the MARS models seemed no longer to add value (relative to linear models) once I began clustering on the predictors.  Apparently, the hinge functions used in the MARS models were acting as a form of ersatz clustering by allowing the otherwise linear coefficients of the predictors to change when certain thresholds were crossed.  Since the cluster models were easier to intepret and had some potential application beyond cement demand, I dropped the MARS models.

### Data filtering and cross-validation

I dropped all the data points with zero cement production, on the grounds that we are using this data as a proxy for demand, and whether or not production was actually zero in those countries during those years, demand almost certainly was not.

I also kept the data only at five-year intervals, starting at 1971 (because that was the earliest year in the cement output database).  This filtering wasn't strictly necessary; the model will fit with all of the data included.  However, many of the quantities are highly correlated from one year to the next, so using all of the datapoints in the regression would render any of the statistical evaluations (F-tests, primarily) of the fit meaningless.  I had originally evaluated the models using data at 10-year intervals, but 5-year data is easier to compare to GCAM.  Therefore, we should be a little skeptical of the p-values returned by the F-tests; however, in most cases the p-values are so far below the traditional thresholds that we can be fairly confident in them.

Approximately 1/5 of the data were held back as a testing set for cross-validation.  These data were chosen as a randomly-selected group of countries, rather than as a randomly-selected group of data rows because of the correlation issue mentioned above.  Holding back, say, China-1986 for cross-validation is rather useless if you include China-1981 and China-1991 in the training set because those data points contain much overlapping information with the point held back.  The hold-back was for the regression analysis; the clustering analysis used all available data, including the testing set.  This was done for technical reasons.  I needed cluster assignments for all data lines in the set, and there isn't a built-in for assigning new data for clusters.  It's not conceptually hard to assign each new data point to the nearest cluster center, but I was trying to hurry, so I took the easy way out.  As a result, the cluster models should not be considered as fully cross-validated.  In practice, I don't think that holding back the testing set will change the clustering much, but there you have it.

The testing countries were chosen when the data set was generated, and they remain constant over subsequent runs (i.e., they are not randomly regenerated each time).  The testing countries are: `r testing.countries`.  Points labeled "testing" in the plots below refer to these countries, while "training" comprises everything else.

### Comparison to GCAM

GCAM models per-capita final demand using 
$$d(t) = d(t-1) \left(\frac{g(t)}{g(t-5)}\right)^{\beta_g} \left(\frac{p(t)}{p(t-5)}\right)^{\beta_p},$$
where $p$ is the price in the relevant supply sector, $d$ is *per-capita* demand, and $\beta_g$ and $\beta_p$ are elasticities that are supplied as input.  They are allowed to vary by region and over time.  With a little rearranging, the first term is evidently identical to our regression formula, minus the intercept term, which GCAM doesn't include.  Since I didn't have historical price data for cement, I wasn't able to include the second term.  This omission undoubtedly accounts for some of the unexplained variance in the models.

The values used for the elasticities in GCAM (at least the version that I have) are all over the map.  Here, for example, are the values used for the Canada and US regions:

year | income elasticity (Canada) | income elasticity (USA)
---- | ----------------- |  ---------------
2020 | 0.35              |   -0.07
2035 | -0.29             |   -0.12
2050 | 0.41              |   -0.25
2065 | -0.14             |   -0.17
2080 | -0.08             |   -0.06
2095 | -0.10             |    -0.02

I'm told that these values have been or are being completely reworked in a recent GCAM release, so I won't spend too much time comparing them to the values that come out of these model fits, other than to note that there doesn't seem to be any evidence in the historical data for negative income elasticities.

## Clustering Analysis

I used the K-means clustering algorithm to sort the data rows into clusters.  Since the clustering is done by data row, a country can move from one cluster to another over time as its economic conditions change.  The K-means algorithm requires a user to specify the number of centers (i.e., clusters) in advance.  I chose 5 centers, based on some trial and error.  With more than 5 centers the resulting clusters "seemed"" poorly-separated.  This is an area that could use some improvement.  There are statistics for evaluating cluster models, as well as advanced clustering algorithms that try to determine the number of clusters supported by the data automatically.

The clusters are summarized by boxplots in each of the cluster variables, as well as the regression variables (which were not used in the clustering algorithm).  The boxes represent the range from the first to third quartile point for the data in each cluster, with the heavy bar showing the median.  The whiskers above and below the boxes show the points within 1.5 times the interquartile range of the upper and lower quartile points.  Outliers beyond the end of the whiskers are plotted individually.  Note that some predictors are shown on a logarithmic y-axis.

We also compute (but do not plot) a "cluster" analysis with just one cluster.  This is for convenience, as it allows us to manipulate a "gcam" style model using the same functions that we use for the cluster models.

```{r simple.clustering, fig.width=10, fig.height=8}
simple.clustervars <- c("pcGDP", "urban.growth", "urban.pop", "pop.rate")
simple.extravars   <- c("pcGDP.rate", "pcc.rate")
simple.plotvars    <- c(simple.clustervars, simple.extravars)
simple.f           <- pcc.rate ~ pcGDP.rate

## Also fit the plain linear model, which we can get by doing just one cluster.
gcam  <- cluster.model(master.table, simple.clustervars, simple.extravars, simple.f, 1,
                        testset=testing.countries)
simple <- cluster.model(master.table, simple.clustervars, simple.extravars, simple.f, 5,
                                   testset=testing.countries)

cluster.boxplot(simple$km, simple$table, simple.plotvars)
```

Looking at the indicator variables for the clusters, we can summarize
the clusters as follows:

1.  Rich, developed countries.<br>
    Examples:  US, Japan, South Korea (2006+)
2.  Upper-middle income countries with moderately-high urbanization and low
    population growth.<br>
    Spot-checking suggests that countries in this group often (but not
    always) stagnate here.<br>
    Examples:  Russia, Hungary, Jamaica (1991+), Ireland (1981--1991)
3.  Low-income, lightly-urbanized countries.<br>
    Examples:  China (-1996), Nepal, Kenya, Albania (-1986)
4.  Upper-middle income countries with high urbanization and high
    population growth.<br>
    The per-capita GDP range for this group overlaps a lot with group
    2, but there is a clear difference in urbanization, urban growth,
    and population growth.<br>
    Examples:  South Korea (1986--2001), Mexico (1981+), Saudi Arabia
    (1981+), Turkey (2006+), Brazil (1981+)
5.  Middle-income, urbanizing countries<br>
    Examples:  China (2001+), Brazil (-1976), Ireland (-1976), Iran
    (-2001), Jamaica (-1986)

Neither per-capita GDP growth factor (*pcGDP.rate*) nor per-capita cement growth factor (*pcc.rate*) show much differentiation between clusters.  This is not surprising, since they were not used in the cluster analysis.  In this case, that's a desirable property, as it makes it likely that we will get relativly robust regressions in all of the clusters.

Plotting the response variable *pcc.rate* against the predictor *pcGDP.rate* reveals that there is a plausible linear (in log-log coordinates, remember) relationship; however, there are also some notable outliers, namely the cluster-2 point at the far right of the plot and the cluster-3 and 5 points at the top-center of the plot.  We can expect these to be poorly fit in the results.  There doesn't seem to be an obvious difference between the clusters, but there isn't obviously *not* a difference either.

```{r rate.plot}
qplot(data=simple$table, x=pcGDP.rate, y=pcc.rate, col=as.factor(simple$km$cluster)) + geom_point(size=0.5) + 
          scale_color_brewer(type="qual", palette="Set1")
```


## Regression model on the clustered data

```{r simple.modeling}
cluster.rms.eval(gcam$km, gcam$table, gcam$model, testing.set=testing.countries)
cluster.rms.eval(simple$km, simple$table, simple$model, testing.set=testing.countries)
cluster.scatterplot.model(gcam$km, gcam$table, gcam$model, sz=2)
cluster.scatterplot.model(simple$km, simple$table, simple$model, sz=2)
```

The cluster model produces a fit that is ever so slightly better (as measured by RMS error) than the unclustered regression, but you couldn't really call it a significant improvement.  The scatterplots look nearly identical, which is kind of surprising, considering how different the model fits are (see below).  

Here are the coefficients for the clustered and unclustered models:

```{r simple.coefs}
lapply(gcam$model, summary)
lapply(simple$model, summary)
```

The "gcam" model (which, unlike GCAM, allows for an intercept term) finds a slope (i.e., elasticity) of `r coef(gcam$model[[1]])[2]`, with no appreciable intercept.  The cluster regressions, on the other hand find coefficients that are in some cases quite different.  Here is a recap of the coefficients in a more compact table:

cluster | slope | intercept
------- | ------ | ---------
1   |  `r coef(simple$model[[1]])[1]` | `r coef(simple$model[[1]])[2]`
2   |  `r coef(simple$model[[2]])[1]` | `r coef(simple$model[[2]])[2]`
3   |  `r coef(simple$model[[3]])[1]` | `r coef(simple$model[[3]])[2]`
4   |  `r coef(simple$model[[4]])[1]` | `r coef(simple$model[[4]])[2]`
5   |  `r coef(simple$model[[5]])[1]` | `r coef(simple$model[[5]])[2]`

The highest coefficient is in the cluster of developed countries, which is surprising until we observe that the effect is offset by the intercept term for all but unusually high-growth countries in that cluster.  Cluster 2 follows a similar pattern.  Cluster 3 (low-income developing nations) has a relatively high elasticity, *without* a compensating intercept term.  Cluster 5 (middle-income nations) has a lower elasticity, and cluster 4 (upper-middle income, high population growth) has an elasticity that is lower still.  These results are roughly consistent with our preconceptions about cement use in the developing world as compared to that in the developed world.

Cluster 4 deserves special mention because the fit of the regression model in that cluster is pretty terrible (for that matter, the fit in cluster 3 isn't spectacular.)  

What does it mean in practice?  Let's take China as an example:

```{r chn.example}
country.clust("CHN", simple$table, simple$km$cluster, simple$model)
```

So, sometime around 2000 China moves from group 3 to group 5. When this happens, the coefficient for its GDP growth rate becomes smaller, though the intercept term offsets that, to some extent.  Presumably, with further growth China would move into either cluster 2 or cluster 4, with attendant reduction in cement usage.

# Conclusions

The first observation I would make is that neither the ordinary regression, nor the cluster regression show any historical evidence for the negative elasticities that we use in GCAM.  It is possible that in the future periods covered by GCAM we may move into new economic regimes where income elasticity for cement demand becomes negative, but such regimes are apparently without precedent in the data we have.

Second, it is not clear that the cluster model provides a significant improvement over an unclustered regression model.  In fact, the RMS errors achieved by the cluster model are almost exactly comparable to the unclustered multivariate regressions that included the variables used in the clustering analysis.  None of the models do a great job of predicting the data, and the residuals do not show any obvious relationship to any of the indicators I tried.  We could go hunting for more indicators, but we do need to be careful to limit ourselves to predictors for which projections covering our GCAM scenarios might plausibly be available.  

One good candidate for an additional indicator, if the data are available, would be cement price.  Since GCAM includes a separate price elasticity, it makes sense to include it in an analysis like this one.  It would be a little surprising if price variations were large enough to account for the huge unexplained variance we are seeing, but it is possible.

Finally, whether we end up using the cluster model for cement demand or not, I think the clustering analysis might be useful for some of the other quantities we have to model.  At least, it provides an alternative to geographical regions for grouping countries.  Perhaps for many purposes it makes more sense to group Paraguay with Angola (group 5) than with Brazil (group 4).
